# [실습1. 한국어 전처리](https://github.com/boostcampaitech3/level2-mrc-level2-nlp-09/blob/develop/EDA/%EC%8B%A4%EC%8A%B51-%ED%95%9C%EA%B5%AD%EC%96%B4_%EC%A0%84%EC%B2%98%EB%A6%AC.ipynb)

### 전처리를 위한 코퍼스 수집

- `newspaper3k` : url 정보만 입력하면 텍스트를 추출해주는 라이브러리 (뉴스 기사의 제목과 내용을 자동으로 분리해줌)
- `remove_html()` : <>가 존재하고 안에 문자가 존재하면 html 태그로 인식해 제거

### 문장 분리

- `kss` : 문장 단위로 모델이 학습하도록 데이터를 문장 단위로 분리 [[github]](https://github.com/hyunwoongko/kss)

### 전처리 함수

- `remove_email()` : 영어@영어.com 형식인 애들을 삭제(이메일은 개인정보이기 때문에 제거하는게 좋음)
- `remove_hashtag()` : 해쉬태그(#)를 제거. `대박! #맛집 #JMT` -> `대박!`
- `remove_user_mention()` : 유저에 대한 멘션(@) 태그를 제거(개인정보일 수 있음) `@홍길동 감사합니다!` ->  `감사합니다!`
- `remove_url()` : url에 개인정보와 가져오지 않아야되는 정보를 포함할 수 있어 제거, 자연어가 url에서 학습할 수 있는게 없기 때문에 제거 `주소: www.naver.com` -> `주소:`
- `remove_bad_char()` : 한국어의 특성 때문에 크롤링하면 이상한 문자가 들어오곤 함, vocab을 생성하거나 모델에 입력할 때 utf-8로 읽히지 않아 에러를 일으키곤 함
- `remove_press()` : 언론 정보 제거. `홍길동 기자 (연합뉴스)` -> 제거
- `remove_copyright()` : 뉴스 내 포함된 저작권 관련 텍스트를 제거
- `remove_photo_info()` : 뉴스 내 포함된 이미지에 대한 label을 제거
- `remove_useless_bracket()` : 위키피디아 전처리를 위한 함수, 괄호 내부에 의미가 없는 정보를 제거. 아무런 정보를 포함하고 있지 않다면, 괄호를 통째로 제거

### 일반화(normalization)

- `soynlp` : 한국어 텍스트 데이터 일반화를 위한 라이브러리?
- `soynlp.normalizer의 repeat_normalize()` : 최대 반복 횟수 이하로 텍스트를 일반화
- `remove_repeat_char()` : 반복되는 텍스트 삭제 `ㅋㅋㅋㅋㅋㅋ` -> `ㅋㅋ`
- `clean_punc()` : 기자마다 다르게 사용한 인용구문 통일
- `remove_repeated_spacing()` : 단어가 삭제된 곳에 연속된 공백이 존재할 수 있음 → 두 개 이상의 연속된 공백을 하나로 치환
- `remove_dup_sent()` : 중복된 문장 제거

### 데이터의 성격에 따라 적용: 띄어쓰기, 문법

- https://github.com/haven-jeon/PyKoSpacing : 기계학습 기반 띄어쓰기 모델
- `sapcing_sent()` : pykospacing을 사용한 띄어쓰기 보정 함수
- https://github.com/ssut/py-hanspell : 맞춤법 검사기 모델
- `spell_check_sent()` : pyhanspell을 사용한 맞춤법 보정 함수
- **기사는 이미 기자가 띄어쓰기를 어느정도 지켰기 때문에 오히려 맞은 띄어쓰기 & 맞춤법을 틀리게 만들 수도 있음**

### 형태소 분석기

- `konlpy` : 한국어 형태소 분석기
- `morph_filter()` : 명사, 동사, 형용사가 한 문장안에 들어있는 데이터만 사용
- `excluded_word_filter()` : 특정 단어를 포함하는 문장 필터링
- `remove_stopwords()` : 불용어 정의 후 제거
- `min_max_filter()` : 문장을 최대, 최소 길이로 필터링

### 유니코드 활용

- 한국인들은 주로 영어, 한국어, 숫자들에 익숙해 있습니다. 그런데 갑자기 러시아어, 아랍어, 불어와 같은 언어들을 처리해야 한다면?!
- 이런 고민을 유니코드를 사용하면 해결할 수 있습니다!
- `remove_language()` : 유니코드를 활용해 vocab(?)에 속하는 단어인지 확인 후 제거

# 실습2. 


# 실습3. 


# 실습4. 
