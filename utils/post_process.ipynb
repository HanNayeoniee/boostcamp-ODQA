{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d7ddf5a-a64e-4160-bcb0-5d14a5a3c541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "from datasets import load_from_disk\n",
    "import string\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47d2c34-b45d-47b2-9304-0c1398d66484",
   "metadata": {},
   "source": [
    "# Reader 데이터 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cbb5090-74e5-4dd6-a44c-2ece84b4adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"input/data/train_dataset\")\n",
    "test_dataset=load_from_disk(\"input/data/test_dataset\")\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "valid_dataset = dataset[\"validation\"]\n",
    "test_dataset=test_dataset['validation']\n",
    "\n",
    "train_df=pd.DataFrame(train_dataset)\n",
    "valid_df=pd.DataFrame(valid_dataset)\n",
    "test_df=pd.DataFrame(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6ea444-5d24-4c0b-8381-44795b94e97a",
   "metadata": {},
   "source": [
    "# Retrieval 데이터 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b4fc564-e553-469e-95d5-9a9661dd0be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"input/data/wikipedia_documents.json\"\n",
    "\n",
    "with open(file_path, \"r\") as json_file:\n",
    "    json_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1165444-cdf8-448e-bf12-0e7efb58eba8",
   "metadata": {},
   "source": [
    "# SOTA , 내 예측 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1223aab5-0975-43bf-a18c-35c44c74a6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sota_path=\"trash/ny.json\"\n",
    "my_pre_path=\"input/level2-mrc-level2-nlp-09/outputs/ae1e-6wu0bs16power2lr9e-6e5_re_check2000_topk40/predictions.json\"\n",
    "\n",
    "with open(sota_path, \"r\") as json_file:\n",
    "    sota= json.load(json_file)\n",
    "with open(my_pre_path, \"r\") as json_file:\n",
    "    my_pre= json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d23171-8814-4624-a4ad-146b5db8d086",
   "metadata": {},
   "source": [
    "# test_df 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9311cd05-4189-4dae-80db-ed75c6758fc1",
   "metadata": {},
   "source": [
    "### 후처리 함수 : [Korquad 공식 사이트의 evaluation script(채점 코드) 참고](https://korquad.github.io/KorQuad%201.0/)\n",
    "#### 후처리 함수 적용과정 : 정의한 불필요한 기호 제거 -> lower -> string.punctuation 제거 -> 공백 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ff8f278-7b21-4a4f-ab89-1da5b1ace68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{']', '#', '@', '{', '*', ':', '?', '&', \"'\", '>', '^', '}', '\"', '-', '/', '$', '<', '!', '.', '[', '+', '~', ',', '%', '\\\\', '=', '_', '(', ';', '|', '`', ')'}\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(set(string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11a62864-87f8-43e7-b5b3-2ae5b7d18dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def normalize_answer(s):    \n",
    "    def remove_(text):\n",
    "        ''' 불필요한 기호 제거 '''\n",
    "        text = re.sub(\"'\", \" \", text)\n",
    "        text = re.sub('\"', \" \", text)\n",
    "        text = re.sub('《', \" \", text)\n",
    "        text = re.sub('》', \" \", text)\n",
    "        text = re.sub('<', \" \", text)\n",
    "        text = re.sub('>', \" \", text) \n",
    "        text = re.sub('〈', \" \", text)\n",
    "        text = re.sub('〉', \" \", text)   \n",
    "        text = re.sub(\"\\(\", \" \", text)\n",
    "        text = re.sub(\"\\)\", \" \", text)\n",
    "        text = re.sub(\"‘\", \" \", text)\n",
    "        text = re.sub(\"’\", \" \", text)      \n",
    "        return text\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_punc(lower(remove_(s))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88391eef-c1ef-40d0-bb2a-308119eb434c",
   "metadata": {},
   "source": [
    "#### 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1368c0eb-f2df-48d5-ada9-fb59bd5870c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'간석기 마제석기'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_answer('간석기(마제석기)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dc3ea2-5fb2-4051-ae51-4d20ef335515",
   "metadata": {},
   "source": [
    "## SOTA 제출과 비교 및 후처리한 항목 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "265187dc-e983-46b7-9b6e-71581a89ed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sota_list=list(sota.values())\n",
    "my_pre_list=list(my_pre.values())\n",
    "\n",
    "diff=[]\n",
    "for js in sota_list:\n",
    "    if js not in my_pre_list:\n",
    "        diff.append(sota_list.index(js))\n",
    "        \n",
    "sota_diff_list=[]\n",
    "my_pre_diff_list=[]\n",
    "\n",
    "for df in diff:\n",
    "    sota_diff_list.append(sota_list[df])\n",
    "    my_pre_diff_list.append(my_pre_list[df])\n",
    "\n",
    "sota_diff=test_df.iloc[diff]\n",
    "sota_diff[\"SOTA_ans\"]=sota_diff_list\n",
    "sota_diff[\"my_ans\"]=my_pre_diff_list\n",
    "sota_diff[\"SOTA_ans_len\"]=list(map(len,sota_diff_list))\n",
    "sota_diff[\"my_ans_len\"]=list(map(len,my_pre_diff_list))\n",
    "sota_diff['post_process(SOTA)']=sota_diff['SOTA_ans'].apply(lambda x: normalize_answer(x))\n",
    "sota_diff['post_process(my)']=sota_diff['my_ans'].apply(lambda x: normalize_answer(x))\n",
    "\n",
    "sota_diff=sota_diff.drop(['id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a7ffaf8-0a62-451c-8a83-fb64c2f63a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################################\n",
      "SOTA와 비교하여 다른 답변의 개수는 229개 입니다.\n",
      "#############################################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>SOTA_ans</th>\n",
       "      <th>my_ans</th>\n",
       "      <th>SOTA_ans_len</th>\n",
       "      <th>my_ans_len</th>\n",
       "      <th>post_process(SOTA)</th>\n",
       "      <th>post_process(my)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>외국인 근로자 고용 등에 대한 법률'의 목적은?</td>\n",
       "      <td>교육 및 문화 교류를 통해 미국 사람들과 다른 국가 사람들 간의 상호 이해를 높이는 것</td>\n",
       "      <td>교육 및 문화 교류를 통해 미국 사람들과 다른 국가 사람들 간의 상호 이해를 높이는</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>교육 및 문화 교류를 통해 미국 사람들과 다른 국가 사람들 간의 상호 이해를 높이는 것</td>\n",
       "      <td>교육 및 문화 교류를 통해 미국 사람들과 다른 국가 사람들 간의 상호 이해를 높이는</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>인민군이 세르비아를 확장하는 쪽으로 돌아서게 만든 사람은?</td>\n",
       "      <td>슬로보단 밀로셰비치의 통제 하로 들어가게 된다. 밀로셰비치</td>\n",
       "      <td>밀로셰비치</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>슬로보단 밀로셰비치의 통제 하로 들어가게 된다 밀로셰비치</td>\n",
       "      <td>밀로셰비치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>연합 함대가 국지 경비 부대와 해상 호위 부대의 인재 육성을 경시해 일어난 결과는?</td>\n",
       "      <td>해상 교통, 보급 확보에 충당해야 할 함정과 인력의 부족</td>\n",
       "      <td>해군의 중요한 임무였던 해상 교통, 보급 확보에 충당해야 할 함정과 인력의 부족</td>\n",
       "      <td>31</td>\n",
       "      <td>44</td>\n",
       "      <td>해상 교통 보급 확보에 충당해야 할 함정과 인력의 부족</td>\n",
       "      <td>해군의 중요한 임무였던 해상 교통 보급 확보에 충당해야 할 함정과 인력의 부족</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>1대부터 4대 칼리파를 통틀어 부른 명칭은?</td>\n",
       "      <td>정통 칼리파(Al-Khalifah Ar-Rashid)</td>\n",
       "      <td>정통 칼리파</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>정통 칼리파 alkhalifah arrashid</td>\n",
       "      <td>정통 칼리파</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>단색 배경에 추상적인 디자인을 쓰는 양식이 유행하던 시기는?</td>\n",
       "      <td>아우구스투스 시대(기원전 27년 ~ 기원후 14년)</td>\n",
       "      <td>아우구스투스 시대</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>아우구스투스 시대 기원전 27년 기원후 14년</td>\n",
       "      <td>아우구스투스 시대</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>하나를 철거하면 열을 건다' 운동에 사용된 플랜카드의 내용은?</td>\n",
       "      <td>'나는 참된 보통 선거를 원한다 (我要真普選)'</td>\n",
       "      <td>'나는 참된 보통 선거를 원한다'</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>나는 참된 보통 선거를 원한다 我要真普選</td>\n",
       "      <td>나는 참된 보통 선거를 원한다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>아일랜드의 자원 공급 불안과 지구 온난화에 대한 해결방안은?</td>\n",
       "      <td>풍력이나 조력 발전 등 대체 에너지의 개발</td>\n",
       "      <td>대체 에너지의 개발</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>풍력이나 조력 발전 등 대체 에너지의 개발</td>\n",
       "      <td>대체 에너지의 개발</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>보디 스타킹에서 봉제되지 않은 부분은?</td>\n",
       "      <td>오른쪽 허벅지 가로 15cm 세로 20cm</td>\n",
       "      <td>연성 수지</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>오른쪽 허벅지 가로 15cm 세로 20cm</td>\n",
       "      <td>연성 수지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>삼탄당 인산 이성질화효소 결핍증은 주로 어떤 물질의 돌연변이로 일어나나요?</td>\n",
       "      <td>104번 위치의 글루탐산이 아스파르트산</td>\n",
       "      <td>아스파르트산</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>104번 위치의 글루탐산이 아스파르트산</td>\n",
       "      <td>아스파르트산</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>인간에게 불타는 느낌의 아픔을 주는 것은?</td>\n",
       "      <td>솔레놉신이 있다. 인간에게는 솔레놉신이</td>\n",
       "      <td>백루검</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>솔레놉신이 있다 인간에게는 솔레놉신이</td>\n",
       "      <td>백루검</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>인간에게 가장 익숙한 크기의 개념은 무엇인가요?</td>\n",
       "      <td>인체의 치수(인체측정학의 측정 기준)</td>\n",
       "      <td>인체의 치수</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>인체의 치수 인체측정학의 측정 기준</td>\n",
       "      <td>인체의 치수</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>행인의 플로이드가 코피난다는 말에 경찰관은 뭐라고 말했는가?</td>\n",
       "      <td>플로이드가 말을 하고 있으니 괜찮다고</td>\n",
       "      <td>괜찮</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>플로이드가 말을 하고 있으니 괜찮다고</td>\n",
       "      <td>괜찮</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>총선에서 듀이를 꺾은 사람은?</td>\n",
       "      <td>현직 대통령 프랭클린 D. 루스벨트</td>\n",
       "      <td>샬럿 리브스</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>현직 대통령 프랭클린 d 루스벨트</td>\n",
       "      <td>샬럿 리브스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>학생이 테스트에서 탈락하고 다시 검증을 받는 과정은 언제까지 반복되는가?</td>\n",
       "      <td>학습자가 정보 통달에 이를 때까지</td>\n",
       "      <td>정보 통달에 이를 때까지</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>학습자가 정보 통달에 이를 때까지</td>\n",
       "      <td>정보 통달에 이를 때까지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>사장이 부하직원에게 행사할 수 있는 권리는 무엇인가?</td>\n",
       "      <td>부하직원의 인사관리에 대한 통제권</td>\n",
       "      <td>인사관리에 대한 통제권</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>부하직원의 인사관리에 대한 통제권</td>\n",
       "      <td>인사관리에 대한 통제권</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>엔도에게 차키를 돌려주려던 사람은？</td>\n",
       "      <td>카에데 소이치로(소리마치 타카시)</td>\n",
       "      <td>카에데 소이치로</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>카에데 소이치로 소리마치 타카시</td>\n",
       "      <td>카에데 소이치로</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>좌운검이 도연이 정조의 자손인 것을 아무도 모르게 하기 위해 한 행동은?</td>\n",
       "      <td>남자아이 빈을 데려다 양자로 삼</td>\n",
       "      <td>남자아이 빈을 데려다 양자</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>남자아이 빈을 데려다 양자로 삼</td>\n",
       "      <td>남자아이 빈을 데려다 양자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>21대 총선을 겨냥하여 사법개혁을 이끌어갈 수 있다는 것에 뒷받침된 명목은?</td>\n",
       "      <td>더불어민주당의 제10호 영입인재</td>\n",
       "      <td>법관 출신 인사</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>더불어민주당의 제10호 영입인재</td>\n",
       "      <td>법관 출신 인사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>듀이는 닉슨을 공천 후보에서 내리는 것이 어떤 결과를 초래할 것이라고 말했는가?</td>\n",
       "      <td>공화당원 투표인들 만을 화나게</td>\n",
       "      <td>공화당원 투표인들 만을</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>공화당원 투표인들 만을 화나게</td>\n",
       "      <td>공화당원 투표인들 만을</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>소설 &lt;형제&gt;의 작가가 태어난 지역은?</td>\n",
       "      <td>프랑스의 브레스트(Brest)</td>\n",
       "      <td>로드아일랜드 주</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>프랑스의 브레스트 brest</td>\n",
       "      <td>로드아일랜드 주</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question  \\\n",
       "337                      외국인 근로자 고용 등에 대한 법률'의 목적은?   \n",
       "543                인민군이 세르비아를 확장하는 쪽으로 돌아서게 만든 사람은?   \n",
       "80   연합 함대가 국지 경비 부대와 해상 호위 부대의 인재 육성을 경시해 일어난 결과는?   \n",
       "342                        1대부터 4대 칼리파를 통틀어 부른 명칭은?   \n",
       "89                단색 배경에 추상적인 디자인을 쓰는 양식이 유행하던 시기는?   \n",
       "569              하나를 철거하면 열을 건다' 운동에 사용된 플랜카드의 내용은?   \n",
       "230               아일랜드의 자원 공급 불안과 지구 온난화에 대한 해결방안은?   \n",
       "378                           보디 스타킹에서 봉제되지 않은 부분은?   \n",
       "491       삼탄당 인산 이성질화효소 결핍증은 주로 어떤 물질의 돌연변이로 일어나나요?   \n",
       "583                         인간에게 불타는 느낌의 아픔을 주는 것은?   \n",
       "463                      인간에게 가장 익숙한 크기의 개념은 무엇인가요?   \n",
       "452               행인의 플로이드가 코피난다는 말에 경찰관은 뭐라고 말했는가?   \n",
       "414                                총선에서 듀이를 꺾은 사람은?   \n",
       "406        학생이 테스트에서 탈락하고 다시 검증을 받는 과정은 언제까지 반복되는가?   \n",
       "444                   사장이 부하직원에게 행사할 수 있는 권리는 무엇인가?   \n",
       "46                              엔도에게 차키를 돌려주려던 사람은？   \n",
       "423        좌운검이 도연이 정조의 자손인 것을 아무도 모르게 하기 위해 한 행동은?   \n",
       "290      21대 총선을 겨냥하여 사법개혁을 이끌어갈 수 있다는 것에 뒷받침된 명목은?   \n",
       "585    듀이는 닉슨을 공천 후보에서 내리는 것이 어떤 결과를 초래할 것이라고 말했는가?   \n",
       "102                           소설 <형제>의 작가가 태어난 지역은?   \n",
       "\n",
       "                                             SOTA_ans  \\\n",
       "337  교육 및 문화 교류를 통해 미국 사람들과 다른 국가 사람들 간의 상호 이해를 높이는 것   \n",
       "543                  슬로보단 밀로셰비치의 통제 하로 들어가게 된다. 밀로셰비치   \n",
       "80                    해상 교통, 보급 확보에 충당해야 할 함정과 인력의 부족   \n",
       "342                     정통 칼리파(Al-Khalifah Ar-Rashid)   \n",
       "89                       아우구스투스 시대(기원전 27년 ~ 기원후 14년)   \n",
       "569                        '나는 참된 보통 선거를 원한다 (我要真普選)'   \n",
       "230                           풍력이나 조력 발전 등 대체 에너지의 개발   \n",
       "378                           오른쪽 허벅지 가로 15cm 세로 20cm   \n",
       "491                             104번 위치의 글루탐산이 아스파르트산   \n",
       "583                             솔레놉신이 있다. 인간에게는 솔레놉신이   \n",
       "463                              인체의 치수(인체측정학의 측정 기준)   \n",
       "452                              플로이드가 말을 하고 있으니 괜찮다고   \n",
       "414                               현직 대통령 프랭클린 D. 루스벨트   \n",
       "406                                학습자가 정보 통달에 이를 때까지   \n",
       "444                                부하직원의 인사관리에 대한 통제권   \n",
       "46                                 카에데 소이치로(소리마치 타카시)   \n",
       "423                                 남자아이 빈을 데려다 양자로 삼   \n",
       "290                                 더불어민주당의 제10호 영입인재   \n",
       "585                                  공화당원 투표인들 만을 화나게   \n",
       "102                                  프랑스의 브레스트(Brest)   \n",
       "\n",
       "                                             my_ans  SOTA_ans_len  my_ans_len  \\\n",
       "337  교육 및 문화 교류를 통해 미국 사람들과 다른 국가 사람들 간의 상호 이해를 높이는            48          46   \n",
       "543                                           밀로셰비치            32           5   \n",
       "80     해군의 중요한 임무였던 해상 교통, 보급 확보에 충당해야 할 함정과 인력의 부족            31          44   \n",
       "342                                          정통 칼리파            29           6   \n",
       "89                                        아우구스투스 시대            28           9   \n",
       "569                              '나는 참된 보통 선거를 원한다'            26          18   \n",
       "230                                      대체 에너지의 개발            23          10   \n",
       "378                                           연성 수지            23           5   \n",
       "491                                          아스파르트산            21           6   \n",
       "583                                             백루검            21           3   \n",
       "463                                          인체의 치수            20           6   \n",
       "452                                              괜찮            20           2   \n",
       "414                                          샬럿 리브스            19           6   \n",
       "406                                   정보 통달에 이를 때까지            18          13   \n",
       "444                                    인사관리에 대한 통제권            18          12   \n",
       "46                                         카에데 소이치로            18           8   \n",
       "423                                  남자아이 빈을 데려다 양자            17          14   \n",
       "290                                        법관 출신 인사            17           8   \n",
       "585                                    공화당원 투표인들 만을            16          12   \n",
       "102                                        로드아일랜드 주            16           8   \n",
       "\n",
       "                                   post_process(SOTA)  \\\n",
       "337  교육 및 문화 교류를 통해 미국 사람들과 다른 국가 사람들 간의 상호 이해를 높이는 것   \n",
       "543                   슬로보단 밀로셰비치의 통제 하로 들어가게 된다 밀로셰비치   \n",
       "80                     해상 교통 보급 확보에 충당해야 할 함정과 인력의 부족   \n",
       "342                        정통 칼리파 alkhalifah arrashid   \n",
       "89                          아우구스투스 시대 기원전 27년 기원후 14년   \n",
       "569                            나는 참된 보통 선거를 원한다 我要真普選   \n",
       "230                           풍력이나 조력 발전 등 대체 에너지의 개발   \n",
       "378                           오른쪽 허벅지 가로 15cm 세로 20cm   \n",
       "491                             104번 위치의 글루탐산이 아스파르트산   \n",
       "583                              솔레놉신이 있다 인간에게는 솔레놉신이   \n",
       "463                               인체의 치수 인체측정학의 측정 기준   \n",
       "452                              플로이드가 말을 하고 있으니 괜찮다고   \n",
       "414                                현직 대통령 프랭클린 d 루스벨트   \n",
       "406                                학습자가 정보 통달에 이를 때까지   \n",
       "444                                부하직원의 인사관리에 대한 통제권   \n",
       "46                                  카에데 소이치로 소리마치 타카시   \n",
       "423                                 남자아이 빈을 데려다 양자로 삼   \n",
       "290                                 더불어민주당의 제10호 영입인재   \n",
       "585                                  공화당원 투표인들 만을 화나게   \n",
       "102                                   프랑스의 브레스트 brest   \n",
       "\n",
       "                                   post_process(my)  \n",
       "337  교육 및 문화 교류를 통해 미국 사람들과 다른 국가 사람들 간의 상호 이해를 높이는  \n",
       "543                                           밀로셰비치  \n",
       "80      해군의 중요한 임무였던 해상 교통 보급 확보에 충당해야 할 함정과 인력의 부족  \n",
       "342                                          정통 칼리파  \n",
       "89                                        아우구스투스 시대  \n",
       "569                                나는 참된 보통 선거를 원한다  \n",
       "230                                      대체 에너지의 개발  \n",
       "378                                           연성 수지  \n",
       "491                                          아스파르트산  \n",
       "583                                             백루검  \n",
       "463                                          인체의 치수  \n",
       "452                                              괜찮  \n",
       "414                                          샬럿 리브스  \n",
       "406                                   정보 통달에 이를 때까지  \n",
       "444                                    인사관리에 대한 통제권  \n",
       "46                                         카에데 소이치로  \n",
       "423                                  남자아이 빈을 데려다 양자  \n",
       "290                                        법관 출신 인사  \n",
       "585                                    공화당원 투표인들 만을  \n",
       "102                                        로드아일랜드 주  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"#############################################################\")\n",
    "print(f\"SOTA와 비교하여 다른 답변의 개수는 {len(sota_diff)}개 입니다.\")\n",
    "print(\"#############################################################\")\n",
    "sota_diff.sort_values(by=[\"SOTA_ans_len\",\"my_ans_len\"],ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a876b4ef-411b-4684-a411-4bd3292fc3d7",
   "metadata": {},
   "source": [
    "# 전체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25876ce4-0891-4d22-9722-9a4c99580357",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>id</th>\n",
       "      <th>SOTA_ans</th>\n",
       "      <th>my_ans</th>\n",
       "      <th>SOTA_ans_len</th>\n",
       "      <th>my_ans_len</th>\n",
       "      <th>post_process(SOTA)</th>\n",
       "      <th>post_process(my)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>외국인 근로자 고용 등에 대한 법률'의 목적은?</td>\n",
       "      <td>mrc-0-004594</td>\n",
       "      <td>교육 및 문화 교류를 통해 미국 사람들과 다른 국가 사람들 간의 상호 이해를 높이는 것</td>\n",
       "      <td>교육 및 문화 교류를 통해 미국 사람들과 다른 국가 사람들 간의 상호 이해를 높이는</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>교육 및 문화 교류를 통해 미국 사람들과 다른 국가 사람들 간의 상호 이해를 높이는 것</td>\n",
       "      <td>교육 및 문화 교류를 통해 미국 사람들과 다른 국가 사람들 간의 상호 이해를 높이는</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>인민군이 세르비아를 확장하는 쪽으로 돌아서게 만든 사람은?</td>\n",
       "      <td>mrc-1-000524</td>\n",
       "      <td>슬로보단 밀로셰비치의 통제 하로 들어가게 된다. 밀로셰비치</td>\n",
       "      <td>밀로셰비치</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>슬로보단 밀로셰비치의 통제 하로 들어가게 된다 밀로셰비치</td>\n",
       "      <td>밀로셰비치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>연합 함대가 국지 경비 부대와 해상 호위 부대의 인재 육성을 경시해 일어난 결과는?</td>\n",
       "      <td>mrc-0-003540</td>\n",
       "      <td>해상 교통, 보급 확보에 충당해야 할 함정과 인력의 부족</td>\n",
       "      <td>해군의 중요한 임무였던 해상 교통, 보급 확보에 충당해야 할 함정과 인력의 부족</td>\n",
       "      <td>31</td>\n",
       "      <td>44</td>\n",
       "      <td>해상 교통 보급 확보에 충당해야 할 함정과 인력의 부족</td>\n",
       "      <td>해군의 중요한 임무였던 해상 교통 보급 확보에 충당해야 할 함정과 인력의 부족</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>1대부터 4대 칼리파를 통틀어 부른 명칭은?</td>\n",
       "      <td>mrc-0-004862</td>\n",
       "      <td>정통 칼리파(Al-Khalifah Ar-Rashid)</td>\n",
       "      <td>정통 칼리파</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>정통 칼리파 alkhalifah arrashid</td>\n",
       "      <td>정통 칼리파</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>단색 배경에 추상적인 디자인을 쓰는 양식이 유행하던 시기는?</td>\n",
       "      <td>mrc-0-003364</td>\n",
       "      <td>아우구스투스 시대(기원전 27년 ~ 기원후 14년)</td>\n",
       "      <td>아우구스투스 시대</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>아우구스투스 시대 기원전 27년 기원후 14년</td>\n",
       "      <td>아우구스투스 시대</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>잉글랜드에서 보리와 함께 가장 많이 경작하는 작물은 무엇인가요?</td>\n",
       "      <td>mrc-0-004538</td>\n",
       "      <td>밀</td>\n",
       "      <td>밀</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>밀</td>\n",
       "      <td>밀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>신돈의 어미니는 어느 곳에 소속된 노비인가?</td>\n",
       "      <td>mrc-1-001035</td>\n",
       "      <td>절</td>\n",
       "      <td>절</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>절</td>\n",
       "      <td>절</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>크라테로스를 사망에 이르게 한 동물은?</td>\n",
       "      <td>mrc-1-000691</td>\n",
       "      <td>말</td>\n",
       "      <td>말</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>말</td>\n",
       "      <td>말</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>수술대 하부에 꿀샘이 존재하면 꽃밥은 어디를 향해 있는가?</td>\n",
       "      <td>mrc-0-000780</td>\n",
       "      <td>밖</td>\n",
       "      <td>밖</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>밖</td>\n",
       "      <td>밖</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>광배는 부처의 육신에서 나오는 어떠한 것을 하나의 형체로 표현한 것인가?</td>\n",
       "      <td>mrc-0-000723</td>\n",
       "      <td>빛</td>\n",
       "      <td>빛</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>빛</td>\n",
       "      <td>빛</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question            id  \\\n",
       "337                      외국인 근로자 고용 등에 대한 법률'의 목적은?  mrc-0-004594   \n",
       "543                인민군이 세르비아를 확장하는 쪽으로 돌아서게 만든 사람은?  mrc-1-000524   \n",
       "80   연합 함대가 국지 경비 부대와 해상 호위 부대의 인재 육성을 경시해 일어난 결과는?  mrc-0-003540   \n",
       "342                        1대부터 4대 칼리파를 통틀어 부른 명칭은?  mrc-0-004862   \n",
       "89                단색 배경에 추상적인 디자인을 쓰는 양식이 유행하던 시기는?  mrc-0-003364   \n",
       "..                                              ...           ...   \n",
       "114             잉글랜드에서 보리와 함께 가장 많이 경작하는 작물은 무엇인가요?  mrc-0-004538   \n",
       "322                        신돈의 어미니는 어느 곳에 소속된 노비인가?  mrc-1-001035   \n",
       "346                           크라테로스를 사망에 이르게 한 동물은?  mrc-1-000691   \n",
       "372                수술대 하부에 꿀샘이 존재하면 꽃밥은 어디를 향해 있는가?  mrc-0-000780   \n",
       "473        광배는 부처의 육신에서 나오는 어떠한 것을 하나의 형체로 표현한 것인가?  mrc-0-000723   \n",
       "\n",
       "                                             SOTA_ans  \\\n",
       "337  교육 및 문화 교류를 통해 미국 사람들과 다른 국가 사람들 간의 상호 이해를 높이는 것   \n",
       "543                  슬로보단 밀로셰비치의 통제 하로 들어가게 된다. 밀로셰비치   \n",
       "80                    해상 교통, 보급 확보에 충당해야 할 함정과 인력의 부족   \n",
       "342                     정통 칼리파(Al-Khalifah Ar-Rashid)   \n",
       "89                       아우구스투스 시대(기원전 27년 ~ 기원후 14년)   \n",
       "..                                                ...   \n",
       "114                                                 밀   \n",
       "322                                                 절   \n",
       "346                                                 말   \n",
       "372                                                 밖   \n",
       "473                                                 빛   \n",
       "\n",
       "                                             my_ans  SOTA_ans_len  my_ans_len  \\\n",
       "337  교육 및 문화 교류를 통해 미국 사람들과 다른 국가 사람들 간의 상호 이해를 높이는            48          46   \n",
       "543                                           밀로셰비치            32           5   \n",
       "80     해군의 중요한 임무였던 해상 교통, 보급 확보에 충당해야 할 함정과 인력의 부족            31          44   \n",
       "342                                          정통 칼리파            29           6   \n",
       "89                                        아우구스투스 시대            28           9   \n",
       "..                                              ...           ...         ...   \n",
       "114                                               밀             1           1   \n",
       "322                                               절             1           1   \n",
       "346                                               말             1           1   \n",
       "372                                               밖             1           1   \n",
       "473                                               빛             1           1   \n",
       "\n",
       "                                   post_process(SOTA)  \\\n",
       "337  교육 및 문화 교류를 통해 미국 사람들과 다른 국가 사람들 간의 상호 이해를 높이는 것   \n",
       "543                   슬로보단 밀로셰비치의 통제 하로 들어가게 된다 밀로셰비치   \n",
       "80                     해상 교통 보급 확보에 충당해야 할 함정과 인력의 부족   \n",
       "342                        정통 칼리파 alkhalifah arrashid   \n",
       "89                          아우구스투스 시대 기원전 27년 기원후 14년   \n",
       "..                                                ...   \n",
       "114                                                 밀   \n",
       "322                                                 절   \n",
       "346                                                 말   \n",
       "372                                                 밖   \n",
       "473                                                 빛   \n",
       "\n",
       "                                   post_process(my)  \n",
       "337  교육 및 문화 교류를 통해 미국 사람들과 다른 국가 사람들 간의 상호 이해를 높이는  \n",
       "543                                           밀로셰비치  \n",
       "80      해군의 중요한 임무였던 해상 교통 보급 확보에 충당해야 할 함정과 인력의 부족  \n",
       "342                                          정통 칼리파  \n",
       "89                                        아우구스투스 시대  \n",
       "..                                              ...  \n",
       "114                                               밀  \n",
       "322                                               절  \n",
       "346                                               말  \n",
       "372                                               밖  \n",
       "473                                               빛  \n",
       "\n",
       "[600 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"SOTA_ans\"]=sota_list\n",
    "test_df[\"my_ans\"]=my_pre_list\n",
    "test_df[\"SOTA_ans_len\"]=test_df[\"SOTA_ans\"].apply(lambda x: len(x))\n",
    "test_df[\"my_ans_len\"]=test_df[\"my_ans\"].apply(lambda x: len(x))\n",
    "test_df['post_process(SOTA)']=test_df['SOTA_ans'].apply(lambda x: normalize_answer(x))\n",
    "test_df['post_process(my)']=test_df['my_ans'].apply(lambda x: normalize_answer(x))\n",
    "test_df.sort_values(by=[\"SOTA_ans_len\",\"my_ans_len\"],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0a716b-f27f-44b2-b4ba-271e8d85c7ed",
   "metadata": {},
   "source": [
    "## 얻은 인사이트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f5139a-a8a3-4fb9-a2be-1a1f9cef42ee",
   "metadata": {},
   "source": [
    "### 1. Korquad 기준으로는 위의 sub->소문자->remove punc->공백제거\n",
    "- \" << \" 기호처럼 부등식을 두개합친 것은 제거가 가능하지만, 밑의 악령 예시처럼 정의되지 않은 기호는 처리 되지 않음\n",
    "- 채점 기준을 명확히 알 수 없기에 함부로 다룰 수 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dd4b45-9c26-49a3-b0a4-e1d2300178ad",
   "metadata": {},
   "source": [
    "![aa](https://user-images.githubusercontent.com/46811558/167540135-143de64b-e694-4110-beba-7d0dbf230c90.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0675444a-9fac-4d7c-8105-ea0b244c0392",
   "metadata": {},
   "source": [
    "### 2. 밑의 예시처럼 명확하지 않지만 직관적으로 틀린 답이 있을 경우 처리\n",
    "- 첫번째, 직접 json을 보며 제거 -> 치팅이라 X\n",
    "- 두번째, 형태소 분석기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16e0e081-41d8-4cf4-a0b7-330b759ef895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>id</th>\n",
       "      <th>SOTA_ans</th>\n",
       "      <th>my_ans</th>\n",
       "      <th>SOTA_ans_len</th>\n",
       "      <th>my_ans_len</th>\n",
       "      <th>post_process(SOTA)</th>\n",
       "      <th>post_process(my)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>인민군이 세르비아를 확장하는 쪽으로 돌아서게 만든 사람은?</td>\n",
       "      <td>mrc-1-000524</td>\n",
       "      <td>슬로보단 밀로셰비치의 통제 하로 들어가게 된다. 밀로셰비치</td>\n",
       "      <td>밀로셰비치</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>슬로보단 밀로셰비치의 통제 하로 들어가게 된다 밀로셰비치</td>\n",
       "      <td>밀로셰비치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>인간에게 불타는 느낌의 아픔을 주는 것은?</td>\n",
       "      <td>mrc-0-001659</td>\n",
       "      <td>솔레놉신이 있다. 인간에게는 솔레놉신이</td>\n",
       "      <td>백루검</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>솔레놉신이 있다 인간에게는 솔레놉신이</td>\n",
       "      <td>백루검</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             question            id  \\\n",
       "543  인민군이 세르비아를 확장하는 쪽으로 돌아서게 만든 사람은?  mrc-1-000524   \n",
       "583           인간에게 불타는 느낌의 아픔을 주는 것은?  mrc-0-001659   \n",
       "\n",
       "                             SOTA_ans my_ans  SOTA_ans_len  my_ans_len  \\\n",
       "543  슬로보단 밀로셰비치의 통제 하로 들어가게 된다. 밀로셰비치  밀로셰비치            32           5   \n",
       "583             솔레놉신이 있다. 인간에게는 솔레놉신이    백루검            21           3   \n",
       "\n",
       "                  post_process(SOTA) post_process(my)  \n",
       "543  슬로보단 밀로셰비치의 통제 하로 들어가게 된다 밀로셰비치            밀로셰비치  \n",
       "583             솔레놉신이 있다 인간에게는 솔레놉신이              백루검  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "josa=[543,583]\n",
    "test_df.iloc[josa]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375dc6ad-f460-445f-8512-0eadb480652f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. 추가적으로 가능한 시도\n",
    "- 앙상블1 : sota의 json을 모아서 후처리 함수 통과한 이후에의 hard voting?\n",
    "    - 추후작성 : [앙상블 실험관련](https://github.com/boostcampaitech3/level2-mrc-level2-nlp-09/issues/45)에서 성능향상 확인 가능\n",
    "    - 답을 정확히 알 수 없기에 명확한 근거는 없지만, 동일 세팅하에 f1 점수 0.11점 상승\n",
    "- 앙상블2 : nbest_prediction 파일을 참고하여 후처리 한 후 소프트 보팅 앙상블\n",
    "    - Ex: 5개의 답변 -> 지구 : 0.3,0.3,0.2 / 화성 0.4,0.7 -> 화성으로 출력\n",
    "- 룰베이스  \n",
    "    ![13](https://user-images.githubusercontent.com/46811558/167543485-7b30bcde-b25a-4044-b6f9-5987c7e5567a.png)\n",
    "- 형태소 분석기\n",
    "    - [소개글](https://couplewith.tistory.com/entry/Python-KoNLPy-%ED%98%95%ED%83%9C%EC%86%8C-%EB%B6%84%EC%84%9D%EA%B8%B0-%EB%B9%84%EA%B5%90-Komoran-Okt-Kkma) -> Komoran ,Okt , Khma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5063e722-b574-4f30-97c5-432d2225db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran, Kkma, Okt, Hannanum\n",
    "komoran = Komoran()\n",
    "kkma = Kkma()\n",
    "okt = Okt()\n",
    "hannanum=Hannanum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37fc3dfe-30d8-4067-a4c1-46628e102254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[슬로보단 밀로셰비치, 의, 통제, 하, 로, 들어가, 게, 되, ㄴ다, ., 밀로셰비치]\n",
      "[슬로보단, 밀로셰비치, 의, 통제, 하, 로, 들, 어, 가, 게, 되, ㄴ다, ., 밀로셰비치]\n",
      "[슬로, 보단, 밀로셰비치, 의, 통제, 하, 로, 들어가게, 된다, ., 밀로셰비치]\n",
      "[슬, ㄹ, 로, 보다, ㄴ, 밀, 로, 셰, 비치, 의, 통제, 하, 로, 들어가, 게, 되, ㄴ다, ., 밀, 로, 셰, 비치]\n",
      "------------\n",
      "['슬로보단 밀로셰비치', '의', '통제', '하', '로', '들어가', '게', '되', 'ㄴ다', '.', '밀로셰비치']\n",
      "['슬로보단', '밀로셰비치', '의', '통제', '하', '로', '들', '어', '가', '게', '되', 'ㄴ다', '.', '밀로셰비치']\n",
      "['슬로', '보단', '밀로셰비치', '의', '통제', '하', '로', '들어가게', '된다', '.', '밀로셰비치']\n",
      "['슬', 'ㄹ', '로', '보다', 'ㄴ', '밀', '로', '셰', '비치', '의', '통제', '하', '로', '들어가', '게', '되', 'ㄴ다', '.', '밀', '로', '셰', '비치']\n"
     ]
    }
   ],
   "source": [
    "sentence='슬로보단 밀로셰비치의 통제 하로 들어가게 된다. 밀로셰비치'\n",
    "class List(list): \n",
    "    def __str__(self): \n",
    "        return \"[\" + \", \".join([\"%s\" % x for x in self]) + \"]\"\n",
    "print(List(komoran.morphs(sentence)))\n",
    "print(List(hannanum.morphs(sentence)))\n",
    "print(List(okt.morphs(sentence)))\n",
    "print(List(kkma.morphs(sentence)))\n",
    "print(\"------------\")\n",
    "print(komoran.morphs(sentence))\n",
    "print(hannanum.morphs(sentence))\n",
    "print(okt.morphs(sentence))\n",
    "print(kkma.morphs(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74d1a37-1fce-4f5c-b9d3-49374e069b6e",
   "metadata": {},
   "source": [
    "### ETC1 : Pororo(NER)\n",
    "- 질문에서 \"누구?,어디?,것?,이유?,사람은?\" 등을 추출하여 난이도 별로 질문 나누기\n",
    "    - 추후에 curriculum learning 가능?\n",
    "    - 국가 -> 프랑스군 vs 프랑스 처럼 아닌 답변 걸러내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fce1b47-02bb-4fd2-96a4-1da9af52fee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Available tasks are ['mrc', 'rc', 'qa', 'question_answering', 'machine_reading_comprehension', 'reading_comprehension', 'sentiment', 'sentiment_analysis', 'nli', 'natural_language_inference', 'inference', 'fill', 'fill_in_blank', 'fib', 'para', 'pi', 'cse', 'contextual_subword_embedding', 'similarity', 'sts', 'semantic_textual_similarity', 'sentence_similarity', 'sentvec', 'sentence_embedding', 'sentence_vector', 'se', 'inflection', 'morphological_inflection', 'g2p', 'grapheme_to_phoneme', 'grapheme_to_phoneme_conversion', 'w2v', 'wordvec', 'word2vec', 'word_vector', 'word_embedding', 'tokenize', 'tokenise', 'tokenization', 'tokenisation', 'tok', 'segmentation', 'seg', 'mt', 'machine_translation', 'translation', 'pos', 'tag', 'pos_tagging', 'tagging', 'const', 'constituency', 'constituency_parsing', 'cp', 'pg', 'collocation', 'collocate', 'col', 'word_translation', 'wt', 'summarization', 'summarisation', 'text_summarization', 'text_summarisation', 'summary', 'gec', 'review', 'review_scoring', 'lemmatization', 'lemmatisation', 'lemma', 'ner', 'named_entity_recognition', 'entity_recognition', 'zero-topic', 'dp', 'dep_parse', 'caption', 'captioning', 'asr', 'speech_recognition', 'st', 'speech_translation', 'tts', 'text_to_speech', 'speech_synthesis', 'ocr', 'srl', 'semantic_role_labeling', 'p2g', 'aes', 'essay', 'qg', 'question_generation', 'age_suitability', 'wsd']\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pororo import Pororo\n",
    "\n",
    "Pororo.available_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2f52833-1f49-40c7-9e2b-e6f25544e08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Korean Sentence Splitter]: Initializing Pynori...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('슬로보', 'PERSON'),\n",
       " ('단', 'O'),\n",
       " (' ', 'O'),\n",
       " ('밀로셰비치', 'PERSON'),\n",
       " ('의', 'O'),\n",
       " (' ', 'O'),\n",
       " ('통제', 'O'),\n",
       " (' ', 'O'),\n",
       " ('하로', 'O'),\n",
       " (' ', 'O'),\n",
       " ('들어가게', 'O'),\n",
       " (' ', 'O'),\n",
       " ('된다.', 'O'),\n",
       " (' ', 'O'),\n",
       " ('밀로셰비치', 'PERSON')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = Pororo(task=\"ner\", lang=\"kor\")\n",
    "ner('슬로보단 밀로셰비치의 통제 하로 들어가게 된다. 밀로셰비치')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4cd55db-3800-4220-8746-a5d3e8ed010e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('인민군', 'ORGANIZATION'),\n",
       " ('이', 'O'),\n",
       " (' ', 'O'),\n",
       " ('세르비아', 'COUNTRY'),\n",
       " ('를', 'O'),\n",
       " (' ', 'O'),\n",
       " ('확장하는', 'O'),\n",
       " (' ', 'O'),\n",
       " ('쪽으로', 'O'),\n",
       " (' ', 'O'),\n",
       " ('돌아서게', 'O'),\n",
       " (' ', 'O'),\n",
       " ('만든', 'O'),\n",
       " (' ', 'O'),\n",
       " ('사람은?', 'O')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner('인민군이 세르비아를 확장하는 쪽으로 돌아서게 만든 사람은?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1be99e-0a56-4e00-9453-3fe50c706aa8",
   "metadata": {},
   "source": [
    "### ETC2 : Pororo(Summarization)\n",
    "- 위키 Retrieval 데이터 전처리 -> summarization 하여 답변 탐색\n",
    "    - 메모리 오류& 문서에서의 답변 사라지는 문제 때문에 제출 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0765f06-8f00-4dfb-a6fb-48f7db31ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "summ = Pororo(task=\"summarization\", model=\"abstractive\", lang=\"ko\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e9b5a18-23f9-4983-94fb-5a3db0bda890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'명 문서는 나라 목록이며, 전 세계 206개 나라의 각 현황과 주권 승인 정보를 개요 형태로 나열하고 있으며 이 목록은 명료화를 위해 두 부분으로 나뉘어 있으며, 두번째 부분은 바티칸 시국과 팔레스타인을 포함하여 유엔 등 국제 기구에 가입되어 국제적인 승인을 널리 받았다고 여기는 195개 나라를 나열하고 있다.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ('이 문서는 나라 목록이며, 전 세계 206개 나라의 각 현황과 주권 승인 정보를 개요 형태로 나열하고 있다.이 목록은 명료화를 위해 두 부분으로 나뉘어 있다.첫 번째 부분은 바티칸 시국과 팔레스타인을 포함하여 유엔 등 국제 기구에 가입되어 국제적인 승인을 널리 받았다고 여기는 195개 나라를 나열하고 있다. 두 번째 부분은 일부 지역의 주권을 사실상 (데 팍토) 행사하고 있지만, 아직 국제적인 승인을 널리 받지 않았다고 여기는 11개 나라를 나열하고 있다.두 목록은 모두 가나다 순이다.일부 국가의 경우 국가로서의 자격에 논쟁의 여부가 있으며, 이 때문에 이러한 목록을 엮는 것은 매우 어렵고 논란이 생길 수 있는 과정이다. 이 목록을 구성하고 있는 국가를 선정하는 기준에 대한 정보는 \"포함 기준\" 단락을 통해 설명하였다. 나라에 대한 일반적인 정보는 \"국가\" 문서에서 설명하고 있다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d970ef2-890e-4589-ac66-fe8195c9f7d6",
   "metadata": {},
   "source": [
    "## [wiki 전처리](https://github.com/boostcampaitech3/level2-mrc-level2-nlp-09/blob/deff4a0e1d4e0977333f97fb7210080e75720843/elastic_setting.py#L39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9efa9d4a-a106-4d33-a960-95e29fe7724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "    text = re.sub(r\"\\\\n\", \" \", text)\n",
    "    text = re.sub(r\"#\", \" \", text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9가-힣.?!,()~‘’“”\"\":%&《》〈〉''㈜·\\-\\'+\\s一-龥サマーン]\", \"\", text)  # サマーン 는 predictions.json에 있었음\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # 두 개 이상의 연속된 공백을 하나로 치환\n",
    "    # text = re.sub(r\"[^A-Za-z0-9가-힣.?!,()~‘’“”\"\":%&《》〈〉''㈜·\\-\\'+\\s一-龥]\", \"\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21e36d5a-a3d2-4b25-96d8-4273991bfdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "\n",
    "file_path = \"input/data/wikipedia_documents.json\"\n",
    "\n",
    "with open(file_path, \"r\",encoding='UTF-8') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "summ_json_path = \"pororo.json\"\n",
    "\n",
    "# with open(del_json_path, 'w', encoding='utf-8') as file:\n",
    "#     json.dump(json_da, file,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d70e067-0737-4d4a-90e5-9866624d4f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list=[]\n",
    "count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75b0180d-0394-4a01-a411-7280692158ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(json_data)):\n\u001b[0;32m----> 2\u001b[0m     json_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43msumm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      3\u001b[0m     count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m count\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m1000\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pororo/tasks/text_summarization.py:258\u001b[0m, in \u001b[0;36mPororoKoBartSummary.__call__\u001b[0;34m(self, text, beam, temperature, top_k, top_p, no_repeat_ngram_size, len_penalty, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    249\u001b[0m     text: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    257\u001b[0m ):\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlen_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m():\n\u001b[0;32m---> 28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pororo/tasks/text_summarization.py:232\u001b[0m, in \u001b[0;36mPororoKoBartSummary.predict\u001b[0;34m(self, text, beam, temperature, top_k, top_p, no_repeat_ngram_size, len_penalty, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m top_k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m top_p \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    230\u001b[0m     sampling \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_topk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_topp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_len_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_len_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlength_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlen_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m():\n\u001b[0;32m---> 28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pororo/models/bart/KoBART.py:167\u001b[0m, in \u001b[0;36mKoBartModel.translate\u001b[0;34m(self, text, beam, sampling, temperature, sampling_topk, sampling_topp, length_penalty, max_len_a, max_len_b, no_repeat_ngram_size, return_tokens, bad_words_ids)\u001b[0m\n\u001b[1;32m    164\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenized[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    165\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m tokenized[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 167\u001b[0m generated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_start_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling_topk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msampling_topk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling_topp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msampling_topk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbad_words_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_tokens_to_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<unk>\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbad_words_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbad_words_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_tokens_to_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<unk>\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlength_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlength_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_len_a\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_len_b\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_tokens:\n\u001b[1;32m    187\u001b[0m     output \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mconvert_ids_to_tokens(_)\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m generated\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    190\u001b[0m     ]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m():\n\u001b[0;32m---> 28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:1056\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, **model_kwargs)\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# interleave with `num_beams`\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1054\u001b[0m         input_ids, expand_size\u001b[38;5;241m=\u001b[39mnum_beams, is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs\n\u001b[1;32m   1055\u001b[0m     )\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_beam_sample_gen_mode:\n\u001b[1;32m   1070\u001b[0m     logits_warper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(\n\u001b[1;32m   1071\u001b[0m         top_k\u001b[38;5;241m=\u001b[39mtop_k, top_p\u001b[38;5;241m=\u001b[39mtop_p, temperature\u001b[38;5;241m=\u001b[39mtemperature, num_beams\u001b[38;5;241m=\u001b[39mnum_beams\n\u001b[1;32m   1072\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:1732\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, **model_kwargs)\u001b[0m\n\u001b[1;32m   1729\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cur_len \u001b[38;5;241m<\u001b[39m max_length:\n\u001b[1;32m   1730\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m-> 1732\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1733\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1734\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1735\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1738\u001b[0m     next_token_logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[1;32m   1740\u001b[0m     \u001b[38;5;66;03m# hack: adjust tokens for Marian. For Marian we have to make sure that the `pad_token_id`\u001b[39;00m\n\u001b[1;32m   1741\u001b[0m     \u001b[38;5;66;03m# cannot be generated both before and after the `F.log_softmax` operation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/bart/modeling_bart.py:1277\u001b[0m, in \u001b[0;36mBartForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1273\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[1;32m   1274\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[1;32m   1275\u001b[0m         )\n\u001b[0;32m-> 1277\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_logits_bias\n\u001b[1;32m   1295\u001b[0m masked_lm_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/bart/modeling_bart.py:1169\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1162\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1163\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1164\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1165\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1166\u001b[0m     )\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1169\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/bart/modeling_bart.py:1039\u001b[0m, in \u001b[0;36mBartDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, encoder_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m   1028\u001b[0m         create_custom_forward(decoder_layer),\n\u001b[1;32m   1029\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1036\u001b[0m     )\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1039\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mencoder_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mencoder_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1050\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/bart/modeling_bart.py:408\u001b[0m, in \u001b[0;36mBartDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, encoder_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    406\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    407\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[0;32m--> 408\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn_layer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# Cross-Attention Block\u001b[39;00m\n\u001b[1;32m    411\u001b[0m cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/normalization.py:189\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2347\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2345\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[1;32m   2346\u001b[0m     )\n\u001b[0;32m-> 2347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "for i in range(len(json_data)):\n",
    "    json_list.append(summ(preprocess(json_data[str(i)]['text'])))\n",
    "    count+=1\n",
    "    if count>1000:\n",
    "        break\n",
    "    # json_data[str(i)]['text']=summ(preprocess(json_data[str(i)]['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8978e1c2-40ef-4b93-b9f7-c003c0505c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이 문서는 나라 목록이며, 전 세계 206개 나라의 각 현황과 주권 승인 정보를 개요 형태로 나열하고 있다.\\n\\n이 목록은 명료화를 위해 두 부분으로 나뉘어 있다.\\n\\n# 첫 번째 부분은 바티칸 시국과 팔레스타인을 포함하여 유엔 등 국제 기구에 가입되어 국제적인 승인을 널리 받았다고 여기는 195개 나라를 나열하고 있다.\\n# 두 번째 부분은 일부 지역의 주권을 사실상 (데 팍토) 행사하고 있지만, 아직 국제적인 승인을 널리 받지 않았다고 여기는 11개 나라를 나열하고 있다.\\n\\n두 목록은 모두 가나다 순이다.\\n\\n일부 국가의 경우 국가로서의 자격에 논쟁의 여부가 있으며, 이 때문에 이러한 목록을 엮는 것은 매우 어렵고 논란이 생길 수 있는 과정이다. 이 목록을 구성하고 있는 국가를 선정하는 기준에 대한 정보는 \"포함 기준\" 단락을 통해 설명하였다. 나라에 대한 일반적인 정보는 \"국가\" 문서에서 설명하고 있다.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data['0']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ade1a7de-e043-4777-9327-38ea3ecdfb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이 문서는 나라 목록이며, 전 세계 206개 나라의 각 현황과 주권 승인 정보를 개요 형태로 나열하고 있으며 이 목록은 명료화를 위해 두 부분으로 나뉘어 있으며, 이 목록은 바티칸 시국과 팔레스타인을 포함하여 유엔 등 국제 기구에 가입되어 국제적인 승인을 널리 받았다고 여기는 195개 나라를 나열하고 있다.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ(preprocess(json_data['0']['text']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
